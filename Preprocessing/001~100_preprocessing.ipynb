{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DataSetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages & libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.ndimage import rotate\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from skimage import measure\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 가속 사용 가능\n",
      "연산 결과: tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU 가속 사용 가능\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU 가속 사용 불가능\")\n",
    "\n",
    "# 간단한 연산을 GPU에서 실행\n",
    "a = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "b = torch.tensor([4.0, 5.0, 6.0], device=device)\n",
    "c = a + b\n",
    "\n",
    "print(\"연산 결과:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores: 48\n"
     ]
    }
   ],
   "source": [
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of available cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_gpus \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of available GPUs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1 Ground Truh Label Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주 데이터 폴더 경로\n",
    "main_data_folder = \"/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast\"\n",
    "image_data_folder = \"/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast/001~100/001~100_screen\"\n",
    "\n",
    "# 세부 폴더의 이름\n",
    "sub_folder_name = '001~100'\n",
    "\n",
    "# 개별 환자 폴더 설정\n",
    "patient_folder_names = [f for f in os.listdir(image_data_folder) if os.path.isdir(os.path.join(image_data_folder, f))]\n",
    "\n",
    "# Find the first Excel file in the directory\n",
    "excel_file_path = glob.glob(f\"{main_data_folder}/{sub_folder_name}/*.xlsx\")[0]\n",
    "excel_data = pd.read_excel(excel_file_path)\n",
    "\n",
    "labels = excel_data['Molecular subtype(1 : luminal A, 2 : luminal B, 3: Her2 positive, 4: Triple negative)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2 Roi Dataset Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병변을 나타내는 색상들의 RGB 값\n",
    "lesion_colors = np.array([\n",
    "    [255, 0, 0],      # Red\n",
    "    [255, 255, 0],    # Yellow1\n",
    "    [255, 102, 0],    # Yellow2\n",
    "    [0, 102, 255],   # Blue1\n",
    "    [0, 0, 255],     # Blue2\n",
    "    [0, 255, 0],    # Green\n",
    "    [128, 0, 255]   # Purple\n",
    "])\n",
    "\n",
    "# DICOM 파일들을 읽고 이미지 데이터를 가져오는 함수\n",
    "def load_patient_images(patient_folder):\n",
    "    \n",
    "    # patient_folder 내의 DICOM 파일들을 가져오기\n",
    "    dicom_files = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # DICOM 파일들을 읽기\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "\n",
    "    # 각 DICOM 파일의 이미지 위치 정보를 기준으로 정렬\n",
    "    dicoms.sort(key=lambda d: float(d.ImagePositionPatient[2]))\n",
    "\n",
    "    # 각 DICOM 파일의 pixel_array를 가져오기\n",
    "    images = np.stack([d.pixel_array for d in dicoms])\n",
    "\n",
    "    return images\n",
    "\n",
    "# 병변 영역을 찾는 함수\n",
    "def find_lesions(images):\n",
    "    lesion_mask = np.any([np.all(images == color, axis=-1) for color in lesion_colors], axis=0)\n",
    "    return lesion_mask\n",
    "\n",
    "# 가장 큰 병변의 Bounding Volume을 찾는 함수\n",
    "def find_largest_lesion_and_bounding_volume(lesion_mask):\n",
    "    \n",
    "    # 3D Connected Component Labeling 수행\n",
    "    labels = measure.label(lesion_mask)\n",
    "\n",
    "    # 각 병변의 크기를 계산하고 가장 큰 병변을 찾기\n",
    "    sizes = np.bincount(labels.ravel())\n",
    "    max_label = sizes[1:].argmax() + 1  # 0 레이블은 배경이므로 제외\n",
    "\n",
    "    # 가장 큰 병변에 해당하는 픽셀들의 좌표를 찾기\n",
    "    lesion_pixels = np.where(labels == max_label)\n",
    "\n",
    "    # bounding volume의 모서리를 찾기\n",
    "    min_corner = np.array([np.min(i) for i in lesion_pixels])\n",
    "    max_corner = np.array([np.max(i) for i in lesion_pixels])\n",
    "\n",
    "    return min_corner, max_corner\n",
    "\n",
    "# DICOM 파일들을 읽고 이미지 데이터를 가져오는 함수\n",
    "def load_dicoms(patient_folder):\n",
    "    \n",
    "    # patient_folder 내의 DICOM 파일들을 가져오기\n",
    "    dicom_files = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # DICOM 파일들을 읽기\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "\n",
    "    # 각 DICOM 파일의 이미지 위치 정보를 기준으로 정렬\n",
    "    dicoms.sort(key=lambda d: float(d.ImagePositionPatient[2]))\n",
    "\n",
    "    # 각 DICOM 파일의 pixel_array를 가져오기\n",
    "    images = np.stack([d.pixel_array for d in dicoms])\n",
    "\n",
    "    return images, dicoms\n",
    "\n",
    "# images를 3D 복셀로 변환합니다.\n",
    "def create_voxel(images, dicoms):\n",
    "    \n",
    "    # 모든 2D DICOM 이미지를 하나의 3D numpy 배열로 결합\n",
    "    voxel = images.astype(float)\n",
    "\n",
    "    # DICOM 파일의 RescaleIntercept와 RescaleSlope를 적용하여 픽셀 값 조정\n",
    "    voxel *= np.float64(dicoms[0].RescaleSlope)\n",
    "    voxel += np.float64(dicoms[0].RescaleIntercept)\n",
    "\n",
    "    return voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patient_folder(patient_folder_name):\n",
    "    \n",
    "    patient_folder_path = os.path.join(image_data_folder, patient_folder_name) # 환자 폴더 경로\n",
    "    folder_list = os.listdir(patient_folder_path)\n",
    "    \n",
    "    # 환자의 일련번호를 patient_num 변수에 저장\n",
    "    patient_num = int(patient_folder_name)\n",
    "\n",
    "    # 'cad'와 'precontrast' 폴더 찾기\n",
    "    cad_folder_name = next(f for f in folder_list if 'cad' in f.lower())\n",
    "    precontrast_folder_name = next(f for f in folder_list if 'precontrast' in f.lower())\n",
    "\n",
    "    # 경로 생성\n",
    "    cad_folder = os.path.join(patient_folder_path, cad_folder_name)\n",
    "    precontrast_folder = os.path.join(patient_folder_path, precontrast_folder_name)\n",
    "\n",
    "    # 각 폴더의 하위 폴더 찾기\n",
    "    cad_subfolder_name = next(f for f in os.listdir(cad_folder) if os.path.isdir(os.path.join(cad_folder, f)))\n",
    "    precontrast_subfolder_name = next(f for f in os.listdir(precontrast_folder) if os.path.isdir(os.path.join(precontrast_folder, f)))\n",
    "\n",
    "    # DICOM 폴더 경로 생성\n",
    "    dicom_folder = os.path.join(cad_folder, cad_subfolder_name)\n",
    "    dicom_folder_pre = os.path.join(precontrast_folder, precontrast_subfolder_name)\n",
    "\n",
    "    # DICOM 이미지들을 로드하기\n",
    "    images = load_patient_images(dicom_folder)\n",
    "    \n",
    "    # 병변 마스크를 생성하기\n",
    "    lesion_mask = find_lesions(images)\n",
    "    \n",
    "    # 가장 큰 병변의 Bounding Volume 찾기\n",
    "    min_corner, max_corner = find_largest_lesion_and_bounding_volume(lesion_mask)\n",
    "    \n",
    "    # DICOM 이미지를 로드하기\n",
    "    images_pre, dicoms_pre = load_dicoms(dicom_folder_pre)\n",
    "    \n",
    "    # images_pre를 3D 복셀로 변환합니다.\n",
    "    voxels_pre = create_voxel(images_pre, dicoms_pre)\n",
    "\n",
    "    # precontrast MRI에서 해당 ROI 잘라내기\n",
    "    roi_precontrast = voxels_pre[min_corner[0]:max_corner[0], min_corner[1]:max_corner[1], min_corner[2]:max_corner[2]]\n",
    "\n",
    "    return patient_num, roi_precontrast\n",
    "\n",
    "# HDF5 파일로 저장하기 위한 h5py.File 인스턴스 생성\n",
    "save_folder = '/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast/001~100/hdf5_001-100' # 저장될 폴더 경로 설정\n",
    "hdf5_file_name = f'{sub_folder_name}_data.h5' # 저장될 HDF5 파일 이름 설정\n",
    "\n",
    "with h5py.File(os.path.join(save_folder, hdf5_file_name), 'w') as hdf5_file:\n",
    "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
    "        for patient_num, roi_precontrast in executor.map(process_patient_folder, patient_folder_names):\n",
    "                                 \n",
    "            # roi_precontrast를 해당 환자의 번호로 HDF5 파일에 저장\n",
    "            hdf5_file.create_dataset(str(patient_num), data=roi_precontrast, chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(143, 87, 142)\n",
      "10\n",
      "(22, 43, 32)\n",
      "100\n",
      "(35, 22, 56)\n",
      "11\n",
      "(34, 77, 42)\n",
      "12\n",
      "(81, 100, 88)\n",
      "13\n",
      "(33, 44, 35)\n",
      "14\n",
      "(70, 34, 77)\n",
      "15\n",
      "(38, 75, 62)\n",
      "16\n",
      "(48, 74, 44)\n",
      "17\n",
      "(30, 80, 45)\n",
      "18\n",
      "(85, 32, 103)\n",
      "19\n",
      "(12, 17, 22)\n",
      "2\n",
      "(56, 26, 99)\n",
      "20\n",
      "(28, 60, 38)\n",
      "21\n",
      "(19, 31, 33)\n",
      "22\n",
      "(25, 41, 42)\n",
      "23\n",
      "(22, 47, 51)\n",
      "24\n",
      "(134, 104, 102)\n",
      "25\n",
      "(27, 31, 26)\n",
      "26\n",
      "(67, 29, 93)\n",
      "27\n",
      "(58, 34, 77)\n",
      "28\n",
      "(15, 40, 17)\n",
      "29\n",
      "(83, 158, 184)\n",
      "3\n",
      "(48, 75, 46)\n",
      "30\n",
      "(122, 93, 76)\n",
      "31\n",
      "(153, 159, 160)\n",
      "32\n",
      "(40, 53, 38)\n",
      "33\n",
      "(68, 48, 50)\n",
      "34\n",
      "(65, 75, 56)\n",
      "35\n",
      "(55, 64, 201)\n",
      "36\n",
      "(106, 74, 52)\n",
      "37\n",
      "(35, 68, 53)\n",
      "38\n",
      "(117, 98, 135)\n",
      "39\n",
      "(97, 133, 132)\n",
      "4\n",
      "(40, 47, 30)\n",
      "40\n",
      "(47, 102, 73)\n",
      "41\n",
      "(86, 132, 108)\n",
      "42\n",
      "(54, 103, 90)\n",
      "43\n",
      "(35, 45, 39)\n",
      "44\n",
      "(58, 30, 76)\n",
      "45\n",
      "(47, 36, 30)\n",
      "46\n",
      "(46, 35, 60)\n",
      "47\n",
      "(25, 32, 25)\n",
      "48\n",
      "(48, 55, 41)\n",
      "49\n",
      "(141, 134, 59)\n",
      "5\n",
      "(14, 29, 55)\n",
      "50\n",
      "(29, 42, 50)\n",
      "51\n",
      "(112, 68, 146)\n",
      "52\n",
      "(34, 62, 64)\n",
      "53\n",
      "(168, 48, 28)\n",
      "54\n",
      "(97, 90, 186)\n",
      "55\n",
      "(84, 50, 106)\n",
      "56\n",
      "(13, 21, 21)\n",
      "57\n",
      "(87, 46, 129)\n",
      "58\n",
      "(67, 64, 54)\n",
      "59\n",
      "(43, 42, 108)\n",
      "6\n",
      "(80, 39, 125)\n",
      "60\n",
      "(58, 116, 191)\n",
      "61\n",
      "(42, 96, 111)\n",
      "62\n",
      "(71, 81, 89)\n",
      "63\n",
      "(32, 22, 45)\n",
      "64\n",
      "(110, 168, 148)\n",
      "65\n",
      "(60, 26, 72)\n",
      "66\n",
      "(17, 30, 27)\n",
      "67\n",
      "(22, 30, 15)\n",
      "68\n",
      "(15, 32, 20)\n",
      "69\n",
      "(12, 36, 26)\n",
      "7\n",
      "(28, 61, 47)\n",
      "70\n",
      "(31, 65, 56)\n",
      "71\n",
      "(77, 33, 99)\n",
      "72\n",
      "(25, 31, 36)\n",
      "73\n",
      "(58, 27, 41)\n",
      "74\n",
      "(32, 97, 51)\n",
      "75\n",
      "(25, 43, 56)\n",
      "76\n",
      "(30, 39, 25)\n",
      "77\n",
      "(147, 170, 202)\n",
      "78\n",
      "(18, 26, 25)\n",
      "79\n",
      "(82, 103, 110)\n",
      "8\n",
      "(67, 42, 15)\n",
      "80\n",
      "(17, 36, 27)\n",
      "81\n",
      "(140, 104, 84)\n",
      "82\n",
      "(33, 17, 36)\n",
      "83\n",
      "(69, 106, 118)\n",
      "84\n",
      "(142, 58, 57)\n",
      "85\n",
      "(84, 91, 121)\n",
      "86\n",
      "(61, 91, 92)\n",
      "87\n",
      "(59, 80, 94)\n",
      "88\n",
      "(19, 34, 30)\n",
      "89\n",
      "(103, 53, 112)\n",
      "9\n",
      "(7, 19, 40)\n",
      "90\n",
      "(19, 31, 23)\n",
      "91\n",
      "(31, 69, 55)\n",
      "92\n",
      "(64, 114, 159)\n",
      "93\n",
      "(88, 32, 13)\n",
      "94\n",
      "(17, 14, 32)\n",
      "95\n",
      "(34, 90, 44)\n",
      "96\n",
      "(35, 30, 115)\n",
      "97\n",
      "(127, 84, 153)\n",
      "98\n",
      "(15, 27, 24)\n",
      "99\n",
      "(131, 172, 159)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# 저장된 HDF5 파일 열기\n",
    "with h5py.File(os.path.join(save_folder, hdf5_file_name), 'r') as hdf5_file:\n",
    "   \n",
    "    # 파일 내에 저장된 모든 데이터셋의 이름 출력\n",
    "    for key in hdf5_file.keys():\n",
    "        print(key)\n",
    "        \n",
    "        # 각 데이터셋의 shape 출력\n",
    "        print(hdf5_file[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 함수\n",
    "def pad_voxel(voxel, max_size):\n",
    "    padding = tuple((max_size[i] - voxel.shape[i]) for i in range(len(max_size)))\n",
    "    padded_voxel = np.pad(voxel, ((0, padding[0]), (0, padding[1]), (0, padding[2])), 'constant', constant_values=0)\n",
    "    return padded_voxel\n",
    "\n",
    "# 모든 ROI 볼륨의 크기를 얻습니다.\n",
    "sizes = [roi.shape for roi in data]\n",
    "\n",
    "# 가장 큰 ROI 볼륨의 크기\n",
    "max_size = np.max(sizes, axis=0)\n",
    "print(max_size)\n",
    "\n",
    "# 가장 작은 ROI 볼륨의 크기\n",
    "min_size = np.min(sizes, axis=0)\n",
    "print(min_size)\n",
    "\n",
    "# 모든 ROI 볼륨에 패딩 추가\n",
    "data = [pad_voxel(roi, max_size) for roi in data]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlab",
   "language": "python",
   "name": "vlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
