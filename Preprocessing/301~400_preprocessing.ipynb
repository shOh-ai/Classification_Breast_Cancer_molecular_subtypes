{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DataSetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages & libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.ndimage import rotate\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from skimage import measure\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 가속 사용 가능\n",
      "연산 결과: tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU 가속 사용 가능\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU 가속 사용 불가능\")\n",
    "\n",
    "# 간단한 연산을 GPU에서 실행\n",
    "a = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "b = torch.tensor([4.0, 5.0, 6.0], device=device)\n",
    "c = a + b\n",
    "\n",
    "print(\"연산 결과:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores: 48\n"
     ]
    }
   ],
   "source": [
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of available cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_gpus \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of available GPUs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1 Ground Truh Label Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주 데이터 폴더 경로\n",
    "main_data_folder = \"/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast\"\n",
    "image_data_folder = \"/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast/301~400/301~400_screen\"\n",
    "\n",
    "# 세부 폴더의 이름\n",
    "sub_folder_name = '301~400'\n",
    "\n",
    "# 개별 환자 폴더 설정\n",
    "patient_folder_names = [f for f in os.listdir(image_data_folder) if os.path.isdir(os.path.join(image_data_folder, f))]\n",
    "\n",
    "# Find the first Excel file in the directory\n",
    "excel_file_path = glob.glob(f\"{main_data_folder}/{sub_folder_name}/*.xlsx\")[0]\n",
    "excel_data = pd.read_excel(excel_file_path)\n",
    "\n",
    "labels = excel_data['Molecular subtype(1 : luminal A, 2 : luminal B, 3: Her2 positive, 4: Triple negative)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2 Roi Dataset Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병변을 나타내는 색상들의 RGB 값\n",
    "lesion_colors = np.array([\n",
    "    [255, 0, 0],      # Red\n",
    "    [255, 255, 0],    # Yellow1\n",
    "    [255, 102, 0],    # Yellow2\n",
    "    [0, 102, 255],   # Blue1\n",
    "    [0, 0, 255],     # Blue2\n",
    "    [0, 255, 0],    # Green\n",
    "    [128, 0, 255]   # Purple\n",
    "])\n",
    "\n",
    "# DICOM 파일들을 읽고 이미지 데이터를 가져오는 함수\n",
    "def load_patient_images(patient_folder):\n",
    "    \n",
    "    # patient_folder 내의 DICOM 파일들을 가져오기\n",
    "    dicom_files = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # DICOM 파일들을 읽기\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "\n",
    "    # 각 DICOM 파일의 이미지 위치 정보를 기준으로 정렬\n",
    "    dicoms.sort(key=lambda d: float(d.ImagePositionPatient[2]))\n",
    "\n",
    "    # 각 DICOM 파일의 pixel_array를 가져오기\n",
    "    images = np.stack([d.pixel_array for d in dicoms])\n",
    "\n",
    "    return images\n",
    "\n",
    "# 병변 영역을 찾는 함수\n",
    "def find_lesions(images):\n",
    "    lesion_mask = np.any([np.all(images == color, axis=-1) for color in lesion_colors], axis=0)\n",
    "    return lesion_mask\n",
    "\n",
    "# 가장 큰 병변의 Bounding Volume을 찾는 함수\n",
    "def find_largest_lesion_and_bounding_volume(lesion_mask):\n",
    "    \n",
    "    # 3D Connected Component Labeling 수행\n",
    "    labels = measure.label(lesion_mask)\n",
    "\n",
    "    # 각 병변의 크기를 계산하고 가장 큰 병변을 찾기\n",
    "    sizes = np.bincount(labels.ravel())\n",
    "    max_label = sizes[1:].argmax() + 1  # 0 레이블은 배경이므로 제외\n",
    "\n",
    "    # 가장 큰 병변에 해당하는 픽셀들의 좌표를 찾기\n",
    "    lesion_pixels = np.where(labels == max_label)\n",
    "\n",
    "    # bounding volume의 모서리를 찾기\n",
    "    min_corner = np.array([np.min(i) for i in lesion_pixels])\n",
    "    max_corner = np.array([np.max(i) for i in lesion_pixels])\n",
    "\n",
    "    return min_corner, max_corner\n",
    "\n",
    "# DICOM 파일들을 읽고 이미지 데이터를 가져오는 함수\n",
    "def load_dicoms(patient_folder):\n",
    "    \n",
    "    # patient_folder 내의 DICOM 파일들을 가져오기\n",
    "    dicom_files = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # DICOM 파일들을 읽기\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "\n",
    "    # 각 DICOM 파일의 이미지 위치 정보를 기준으로 정렬\n",
    "    dicoms.sort(key=lambda d: float(d.ImagePositionPatient[2]))\n",
    "\n",
    "    # 각 DICOM 파일의 pixel_array를 가져오기\n",
    "    images = np.stack([d.pixel_array for d in dicoms])\n",
    "\n",
    "    return images, dicoms\n",
    "\n",
    "# images를 3D 복셀로 변환합니다.\n",
    "def create_voxel(images, dicoms):\n",
    "    \n",
    "    # 모든 2D DICOM 이미지를 하나의 3D numpy 배열로 결합\n",
    "    voxel = images.astype(float)\n",
    "\n",
    "    # DICOM 파일의 RescaleIntercept와 RescaleSlope를 적용하여 픽셀 값 조정\n",
    "    voxel *= np.float64(dicoms[0].RescaleSlope)\n",
    "    voxel += np.float64(dicoms[0].RescaleIntercept)\n",
    "\n",
    "    return voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patient_folder(patient_folder_name):\n",
    "    \n",
    "    patient_folder_path = os.path.join(image_data_folder, patient_folder_name) # 환자 폴더 경로\n",
    "    folder_list = os.listdir(patient_folder_path)\n",
    "    \n",
    "    # 환자의 일련번호를 patient_num 변수에 저장\n",
    "    patient_num = int(patient_folder_name)\n",
    "\n",
    "    # 'cad'와 'precontrast' 폴더 찾기\n",
    "    cad_folder_name = next(f for f in folder_list if 'cad' in f.lower())\n",
    "    precontrast_folder_name = next(f for f in folder_list if 'precontrast' in f.lower())\n",
    "\n",
    "    # 경로 생성\n",
    "    cad_folder = os.path.join(patient_folder_path, cad_folder_name)\n",
    "    precontrast_folder = os.path.join(patient_folder_path, precontrast_folder_name)\n",
    "\n",
    "    # 각 폴더의 하위 폴더 찾기\n",
    "    cad_subfolder_name = next(f for f in os.listdir(cad_folder) if os.path.isdir(os.path.join(cad_folder, f)))\n",
    "    precontrast_subfolder_name = next(f for f in os.listdir(precontrast_folder) if os.path.isdir(os.path.join(precontrast_folder, f)))\n",
    "\n",
    "    # DICOM 폴더 경로 생성\n",
    "    dicom_folder = os.path.join(cad_folder, cad_subfolder_name)\n",
    "    dicom_folder_pre = os.path.join(precontrast_folder, precontrast_subfolder_name)\n",
    "\n",
    "    # DICOM 이미지들을 로드하기\n",
    "    images = load_patient_images(dicom_folder)\n",
    "    \n",
    "    # 병변 마스크를 생성하기\n",
    "    lesion_mask = find_lesions(images)\n",
    "    \n",
    "    # 가장 큰 병변의 Bounding Volume 찾기\n",
    "    min_corner, max_corner = find_largest_lesion_and_bounding_volume(lesion_mask)\n",
    "    \n",
    "    # DICOM 이미지를 로드하기\n",
    "    images_pre, dicoms_pre = load_dicoms(dicom_folder_pre)\n",
    "    \n",
    "    # images_pre를 3D 복셀로 변환합니다.\n",
    "    voxels_pre = create_voxel(images_pre, dicoms_pre)\n",
    "\n",
    "    # precontrast MRI에서 해당 ROI 잘라내기\n",
    "    roi_precontrast = voxels_pre[min_corner[0]:max_corner[0], min_corner[1]:max_corner[1], min_corner[2]:max_corner[2]]\n",
    "\n",
    "    return patient_num, roi_precontrast\n",
    "\n",
    "# HDF5 파일로 저장하기 위한 h5py.File 인스턴스 생성\n",
    "save_folder = '/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast/301~400/hdf5_301-400' # 저장될 폴더 경로 설정\n",
    "hdf5_file_name = f'{sub_folder_name}_data.h5' # 저장될 HDF5 파일 이름 설정\n",
    "\n",
    "with h5py.File(os.path.join(save_folder, hdf5_file_name), 'w') as hdf5_file:\n",
    "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
    "        for patient_num, roi_precontrast in executor.map(process_patient_folder, patient_folder_names):\n",
    "                                 \n",
    "            # roi_precontrast를 해당 환자의 번호로 HDF5 파일에 저장\n",
    "            hdf5_file.create_dataset(str(patient_num), data=roi_precontrast, chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n",
      "(79, 91, 264)\n",
      "302\n",
      "(110, 134, 133)\n",
      "303\n",
      "(44, 79, 100)\n",
      "304\n",
      "(71, 46, 152)\n",
      "305\n",
      "(13, 35, 23)\n",
      "306\n",
      "(57, 87, 217)\n",
      "307\n",
      "(116, 161, 390)\n",
      "308\n",
      "(86, 105, 334)\n",
      "309\n",
      "(60, 145, 105)\n",
      "310\n",
      "(77, 135, 217)\n",
      "311\n",
      "(67, 20, 48)\n",
      "312\n",
      "(47, 35, 90)\n",
      "313\n",
      "(20, 49, 29)\n",
      "314\n",
      "(120, 175, 195)\n",
      "315\n",
      "(26, 134, 81)\n",
      "316\n",
      "(21, 23, 38)\n",
      "317\n",
      "(118, 160, 203)\n",
      "318\n",
      "(104, 27, 118)\n",
      "319\n",
      "(113, 95, 98)\n",
      "320\n",
      "(97, 198, 86)\n",
      "321\n",
      "(76, 73, 138)\n",
      "322\n",
      "(40, 95, 48)\n",
      "323\n",
      "(68, 87, 212)\n",
      "324\n",
      "(41, 89, 42)\n",
      "325\n",
      "(134, 121, 173)\n",
      "326\n",
      "(30, 39, 52)\n",
      "327\n",
      "(106, 81, 150)\n",
      "328\n",
      "(67, 105, 113)\n",
      "329\n",
      "(96, 136, 100)\n",
      "330\n",
      "(29, 29, 40)\n",
      "331\n",
      "(20, 66, 25)\n",
      "332\n",
      "(15, 27, 29)\n",
      "333\n",
      "(133, 109, 194)\n",
      "334\n",
      "(62, 32, 71)\n",
      "335\n",
      "(75, 122, 74)\n",
      "336\n",
      "(94, 134, 137)\n",
      "337\n",
      "(24, 34, 37)\n",
      "338\n",
      "(117, 155, 175)\n",
      "339\n",
      "(126, 157, 211)\n",
      "340\n",
      "(123, 47, 20)\n",
      "341\n",
      "(19, 31, 26)\n",
      "342\n",
      "(64, 87, 58)\n",
      "343\n",
      "(151, 241, 408)\n",
      "344\n",
      "(19, 31, 29)\n",
      "345\n",
      "(25, 59, 37)\n",
      "346\n",
      "(51, 32, 48)\n",
      "347\n",
      "(38, 45, 35)\n",
      "348\n",
      "(41, 100, 74)\n",
      "349\n",
      "(37, 126, 87)\n",
      "350\n",
      "(112, 160, 196)\n",
      "351\n",
      "(89, 86, 69)\n",
      "352\n",
      "(42, 97, 55)\n",
      "353\n",
      "(32, 20, 53)\n",
      "354\n",
      "(72, 65, 70)\n",
      "355\n",
      "(51, 43, 78)\n",
      "356\n",
      "(62, 15, 72)\n",
      "357\n",
      "(74, 92, 102)\n",
      "358\n",
      "(24, 55, 55)\n",
      "359\n",
      "(94, 85, 101)\n",
      "360\n",
      "(51, 110, 101)\n",
      "361\n",
      "(139, 172, 387)\n",
      "362\n",
      "(45, 109, 79)\n",
      "363\n",
      "(46, 52, 39)\n",
      "364\n",
      "(9, 17, 22)\n",
      "365\n",
      "(64, 67, 208)\n",
      "366\n",
      "(157, 54, 62)\n",
      "367\n",
      "(111, 124, 265)\n",
      "368\n",
      "(111, 187, 65)\n",
      "369\n",
      "(77, 55, 80)\n",
      "370\n",
      "(51, 5, 42)\n",
      "371\n",
      "(126, 109, 147)\n",
      "372\n",
      "(59, 96, 81)\n",
      "373\n",
      "(51, 37, 117)\n",
      "374\n",
      "(84, 117, 75)\n",
      "375\n",
      "(103, 86, 112)\n",
      "376\n",
      "(80, 62, 41)\n",
      "377\n",
      "(92, 132, 246)\n",
      "378\n",
      "(125, 225, 190)\n",
      "379\n",
      "(69, 128, 222)\n",
      "380\n",
      "(26, 49, 42)\n",
      "381\n",
      "(39, 48, 58)\n",
      "382\n",
      "(19, 35, 35)\n",
      "383\n",
      "(10, 22, 20)\n",
      "384\n",
      "(22, 49, 37)\n",
      "385\n",
      "(110, 161, 140)\n",
      "386\n",
      "(53, 89, 105)\n",
      "387\n",
      "(60, 46, 92)\n",
      "388\n",
      "(10, 17, 19)\n",
      "389\n",
      "(18, 49, 34)\n",
      "390\n",
      "(36, 42, 34)\n",
      "391\n",
      "(47, 27, 69)\n",
      "392\n",
      "(77, 157, 165)\n",
      "393\n",
      "(46, 37, 76)\n",
      "394\n",
      "(39, 71, 76)\n",
      "395\n",
      "(47, 46, 33)\n",
      "396\n",
      "(26, 66, 39)\n",
      "397\n",
      "(22, 23, 29)\n",
      "398\n",
      "(14, 30, 23)\n",
      "399\n",
      "(23, 47, 38)\n",
      "400\n",
      "(91, 178, 220)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# 저장된 HDF5 파일 열기\n",
    "with h5py.File(os.path.join(save_folder, hdf5_file_name), 'r') as hdf5_file:\n",
    "   \n",
    "    # 파일 내에 저장된 모든 데이터셋의 이름 출력\n",
    "    for key in hdf5_file.keys():\n",
    "        print(key)\n",
    "        \n",
    "        # 각 데이터셋의 shape 출력\n",
    "        print(hdf5_file[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlab",
   "language": "python",
   "name": "vlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
