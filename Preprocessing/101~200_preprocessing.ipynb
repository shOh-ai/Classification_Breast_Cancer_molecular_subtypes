{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DataSetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages & libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.ndimage import rotate\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from skimage import measure\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 가속 사용 가능\n",
      "연산 결과: tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU 가속 사용 가능\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU 가속 사용 불가능\")\n",
    "\n",
    "# 간단한 연산을 GPU에서 실행\n",
    "a = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "b = torch.tensor([4.0, 5.0, 6.0], device=device)\n",
    "c = a + b\n",
    "\n",
    "print(\"연산 결과:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores: 48\n"
     ]
    }
   ],
   "source": [
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of available cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_gpus \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of available GPUs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_gpus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1 Ground Truh Label Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주 데이터 폴더 경로\n",
    "main_data_folder = \"/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast\"\n",
    "image_data_folder = \"/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast/101~200/101~200_screen\"\n",
    "\n",
    "# 세부 폴더의 이름\n",
    "sub_folder_name = '101~200'\n",
    "\n",
    "# 개별 환자 폴더 설정\n",
    "patient_folder_names = [f for f in os.listdir(image_data_folder) if os.path.isdir(os.path.join(image_data_folder, f))]\n",
    "\n",
    "# Find the first Excel file in the directory\n",
    "excel_file_path = glob.glob(f\"{main_data_folder}/{sub_folder_name}/*.xlsx\")[0]\n",
    "excel_data = pd.read_excel(excel_file_path)\n",
    "\n",
    "labels = excel_data['Molecular subtype(1 : luminal A, 2 : luminal B, 3: Her2 positive, 4: Triple negative)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2 Roi Dataset Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병변을 나타내는 색상들의 RGB 값\n",
    "lesion_colors = np.array([\n",
    "    [255, 0, 0],      # Red\n",
    "    [255, 255, 0],    # Yellow1\n",
    "    [255, 102, 0],    # Yellow2\n",
    "    [0, 102, 255],   # Blue1\n",
    "    [0, 0, 255],     # Blue2\n",
    "    [0, 255, 0],    # Green\n",
    "    [128, 0, 255]   # Purple\n",
    "])\n",
    "\n",
    "# DICOM 파일들을 읽고 이미지 데이터를 가져오는 함수\n",
    "def load_patient_images(patient_folder):\n",
    "    \n",
    "    # patient_folder 내의 DICOM 파일들을 가져오기\n",
    "    dicom_files = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # DICOM 파일들을 읽기\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "\n",
    "    # 각 DICOM 파일의 이미지 위치 정보를 기준으로 정렬\n",
    "    dicoms.sort(key=lambda d: float(d.ImagePositionPatient[2]))\n",
    "\n",
    "    # 각 DICOM 파일의 pixel_array를 가져오기\n",
    "    images = np.stack([d.pixel_array for d in dicoms])\n",
    "\n",
    "    return images\n",
    "\n",
    "# 병변 영역을 찾는 함수\n",
    "def find_lesions(images):\n",
    "    lesion_mask = np.any([np.all(images == color, axis=-1) for color in lesion_colors], axis=0)\n",
    "    return lesion_mask\n",
    "\n",
    "# 가장 큰 병변의 Bounding Volume을 찾는 함수\n",
    "def find_largest_lesion_and_bounding_volume(lesion_mask):\n",
    "    \n",
    "    # 3D Connected Component Labeling 수행\n",
    "    labels = measure.label(lesion_mask)\n",
    "\n",
    "    # 각 병변의 크기를 계산하고 가장 큰 병변을 찾기\n",
    "    sizes = np.bincount(labels.ravel())\n",
    "    max_label = sizes[1:].argmax() + 1  # 0 레이블은 배경이므로 제외\n",
    "\n",
    "    # 가장 큰 병변에 해당하는 픽셀들의 좌표를 찾기\n",
    "    lesion_pixels = np.where(labels == max_label)\n",
    "\n",
    "    # bounding volume의 모서리를 찾기\n",
    "    min_corner = np.array([np.min(i) for i in lesion_pixels])\n",
    "    max_corner = np.array([np.max(i) for i in lesion_pixels])\n",
    "\n",
    "    return min_corner, max_corner\n",
    "\n",
    "# DICOM 파일들을 읽고 이미지 데이터를 가져오는 함수\n",
    "def load_dicoms(patient_folder):\n",
    "    \n",
    "    # patient_folder 내의 DICOM 파일들을 가져오기\n",
    "    dicom_files = [os.path.join(patient_folder, f) for f in os.listdir(patient_folder) if f.endswith('.dcm')]\n",
    "\n",
    "    # DICOM 파일들을 읽기\n",
    "    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n",
    "\n",
    "    # 각 DICOM 파일의 이미지 위치 정보를 기준으로 정렬\n",
    "    dicoms.sort(key=lambda d: float(d.ImagePositionPatient[2]))\n",
    "\n",
    "    # 각 DICOM 파일의 pixel_array를 가져오기\n",
    "    images = np.stack([d.pixel_array for d in dicoms])\n",
    "\n",
    "    return images, dicoms\n",
    "\n",
    "# images를 3D 복셀로 변환합니다.\n",
    "def create_voxel(images, dicoms):\n",
    "    \n",
    "    # 모든 2D DICOM 이미지를 하나의 3D numpy 배열로 결합\n",
    "    voxel = images.astype(float)\n",
    "\n",
    "    # DICOM 파일의 RescaleIntercept와 RescaleSlope를 적용하여 픽셀 값 조정\n",
    "    voxel *= np.float64(dicoms[0].RescaleSlope)\n",
    "    voxel += np.float64(dicoms[0].RescaleIntercept)\n",
    "\n",
    "    return voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patient_folder(patient_folder_name):\n",
    "    \n",
    "    patient_folder_path = os.path.join(image_data_folder, patient_folder_name) # 환자 폴더 경로\n",
    "    folder_list = os.listdir(patient_folder_path)\n",
    "    \n",
    "    # 환자의 일련번호를 patient_num 변수에 저장\n",
    "    patient_num = int(patient_folder_name)\n",
    "\n",
    "    # 'cad'와 'precontrast' 폴더 찾기\n",
    "    cad_folder_name = next(f for f in folder_list if 'cad' in f.lower())\n",
    "    precontrast_folder_name = next(f for f in folder_list if 'precontrast' in f.lower())\n",
    "\n",
    "    # 경로 생성\n",
    "    cad_folder = os.path.join(patient_folder_path, cad_folder_name)\n",
    "    precontrast_folder = os.path.join(patient_folder_path, precontrast_folder_name)\n",
    "\n",
    "    # 각 폴더의 하위 폴더 찾기\n",
    "    cad_subfolder_name = next(f for f in os.listdir(cad_folder) if os.path.isdir(os.path.join(cad_folder, f)))\n",
    "    precontrast_subfolder_name = next(f for f in os.listdir(precontrast_folder) if os.path.isdir(os.path.join(precontrast_folder, f)))\n",
    "\n",
    "    # DICOM 폴더 경로 생성\n",
    "    dicom_folder = os.path.join(cad_folder, cad_subfolder_name)\n",
    "    dicom_folder_pre = os.path.join(precontrast_folder, precontrast_subfolder_name)\n",
    "\n",
    "    # DICOM 이미지들을 로드하기\n",
    "    images = load_patient_images(dicom_folder)\n",
    "    \n",
    "    # 병변 마스크를 생성하기\n",
    "    lesion_mask = find_lesions(images)\n",
    "    \n",
    "    # 가장 큰 병변의 Bounding Volume 찾기\n",
    "    min_corner, max_corner = find_largest_lesion_and_bounding_volume(lesion_mask)\n",
    "    \n",
    "    # DICOM 이미지를 로드하기\n",
    "    images_pre, dicoms_pre = load_dicoms(dicom_folder_pre)\n",
    "    \n",
    "    # images_pre를 3D 복셀로 변환합니다.\n",
    "    voxels_pre = create_voxel(images_pre, dicoms_pre)\n",
    "\n",
    "    # precontrast MRI에서 해당 ROI 잘라내기\n",
    "    roi_precontrast = voxels_pre[min_corner[0]:max_corner[0], min_corner[1]:max_corner[1], min_corner[2]:max_corner[2]]\n",
    "\n",
    "    return patient_num, roi_precontrast\n",
    "\n",
    "# HDF5 파일로 저장하기 위한 h5py.File 인스턴스 생성\n",
    "save_folder = '/home/osh/data/vlabhufs.ipdisk.co.kr/VOL1/Storage1/Data/SNUBH_Breast/101~200/hdf5_101-200' # 저장될 폴더 경로 설정\n",
    "hdf5_file_name = f'{sub_folder_name}_data.h5' # 저장될 HDF5 파일 이름 설정\n",
    "\n",
    "with h5py.File(os.path.join(save_folder, hdf5_file_name), 'w') as hdf5_file:\n",
    "    with ProcessPoolExecutor(max_workers=30) as executor:\n",
    "        for patient_num, roi_precontrast in executor.map(process_patient_folder, patient_folder_names):\n",
    "                                 \n",
    "            # roi_precontrast를 해당 환자의 번호로 HDF5 파일에 저장\n",
    "            hdf5_file.create_dataset(str(patient_num), data=roi_precontrast, chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "(112, 274, 266)\n",
      "102\n",
      "(23, 26, 30)\n",
      "103\n",
      "(17, 34, 33)\n",
      "104\n",
      "(120, 118, 355)\n",
      "105\n",
      "(104, 135, 176)\n",
      "106\n",
      "(38, 67, 65)\n",
      "107\n",
      "(43, 48, 100)\n",
      "108\n",
      "(84, 40, 94)\n",
      "109\n",
      "(88, 178, 165)\n",
      "110\n",
      "(94, 40, 21)\n",
      "111\n",
      "(137, 187, 158)\n",
      "112\n",
      "(17, 38, 33)\n",
      "113\n",
      "(135, 102, 77)\n",
      "114\n",
      "(77, 88, 60)\n",
      "115\n",
      "(107, 59, 151)\n",
      "116\n",
      "(135, 176, 187)\n",
      "117\n",
      "(88, 30, 100)\n",
      "118\n",
      "(39, 42, 72)\n",
      "119\n",
      "(57, 30, 118)\n",
      "120\n",
      "(48, 98, 57)\n",
      "121\n",
      "(32, 28, 45)\n",
      "122\n",
      "(12, 20, 36)\n",
      "123\n",
      "(35, 35, 86)\n",
      "124\n",
      "(40, 37, 82)\n",
      "125\n",
      "(25, 57, 42)\n",
      "126\n",
      "(35, 48, 45)\n",
      "127\n",
      "(103, 166, 176)\n",
      "128\n",
      "(53, 34, 83)\n",
      "129\n",
      "(66, 74, 49)\n",
      "130\n",
      "(43, 34, 68)\n",
      "131\n",
      "(55, 31, 96)\n",
      "132\n",
      "(30, 69, 49)\n",
      "133\n",
      "(66, 116, 173)\n",
      "134\n",
      "(63, 65, 113)\n",
      "135\n",
      "(75, 100, 192)\n",
      "136\n",
      "(19, 53, 37)\n",
      "137\n",
      "(46, 41, 107)\n",
      "138\n",
      "(135, 201, 357)\n",
      "139\n",
      "(91, 67, 62)\n",
      "140\n",
      "(134, 189, 204)\n",
      "141\n",
      "(13, 25, 20)\n",
      "142\n",
      "(107, 157, 93)\n",
      "143\n",
      "(105, 139, 240)\n",
      "144\n",
      "(31, 33, 39)\n",
      "145\n",
      "(58, 34, 106)\n",
      "146\n",
      "(82, 84, 134)\n",
      "147\n",
      "(111, 12, 23)\n",
      "148\n",
      "(121, 162, 169)\n",
      "149\n",
      "(86, 175, 108)\n",
      "150\n",
      "(142, 57, 100)\n",
      "151\n",
      "(85, 14, 23)\n",
      "152\n",
      "(102, 183, 82)\n",
      "153\n",
      "(118, 149, 204)\n",
      "154\n",
      "(33, 132, 44)\n",
      "155\n",
      "(26, 48, 70)\n",
      "156\n",
      "(35, 19, 46)\n",
      "157\n",
      "(56, 116, 78)\n",
      "158\n",
      "(105, 94, 262)\n",
      "159\n",
      "(111, 105, 61)\n",
      "160\n",
      "(15, 32, 26)\n",
      "161\n",
      "(146, 71, 40)\n",
      "162\n",
      "(139, 158, 293)\n",
      "163\n",
      "(77, 82, 125)\n",
      "164\n",
      "(89, 46, 155)\n",
      "165\n",
      "(59, 14, 81)\n",
      "166\n",
      "(102, 58, 24)\n",
      "167\n",
      "(22, 52, 29)\n",
      "168\n",
      "(95, 108, 240)\n",
      "169\n",
      "(53, 33, 88)\n",
      "170\n",
      "(62, 125, 79)\n",
      "171\n",
      "(128, 92, 198)\n",
      "172\n",
      "(77, 71, 85)\n",
      "173\n",
      "(68, 40, 112)\n",
      "174\n",
      "(86, 68, 64)\n",
      "175\n",
      "(98, 115, 45)\n",
      "176\n",
      "(122, 70, 57)\n",
      "177\n",
      "(19, 42, 36)\n",
      "178\n",
      "(84, 91, 193)\n",
      "179\n",
      "(128, 206, 385)\n",
      "180\n",
      "(47, 37, 98)\n",
      "181\n",
      "(95, 37, 22)\n",
      "182\n",
      "(25, 41, 30)\n",
      "183\n",
      "(124, 178, 241)\n",
      "184\n",
      "(61, 99, 36)\n",
      "185\n",
      "(115, 142, 160)\n",
      "186\n",
      "(58, 22, 40)\n",
      "187\n",
      "(151, 208, 344)\n",
      "188\n",
      "(12, 60, 51)\n",
      "189\n",
      "(124, 151, 194)\n",
      "190\n",
      "(49, 20, 59)\n",
      "191\n",
      "(73, 84, 70)\n",
      "192\n",
      "(67, 6, 59)\n",
      "193\n",
      "(64, 172, 166)\n",
      "194\n",
      "(32, 15, 39)\n",
      "195\n",
      "(34, 52, 64)\n",
      "196\n",
      "(121, 200, 417)\n",
      "197\n",
      "(133, 97, 85)\n",
      "198\n",
      "(25, 98, 42)\n",
      "199\n",
      "(23, 31, 45)\n",
      "200\n",
      "(89, 54, 117)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# 저장된 HDF5 파일 열기\n",
    "with h5py.File(os.path.join(save_folder, hdf5_file_name), 'r') as hdf5_file:\n",
    "   \n",
    "    # 파일 내에 저장된 모든 데이터셋의 이름 출력\n",
    "    for key in hdf5_file.keys():\n",
    "        print(key)\n",
    "        \n",
    "        # 각 데이터셋의 shape 출력\n",
    "        print(hdf5_file[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlab",
   "language": "python",
   "name": "vlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
